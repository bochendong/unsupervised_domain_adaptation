{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from torch.autograd import Function\n",
    "import load_mnist_data\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import torch.backends.cudnn as cudnn\n",
    "import random\n",
    "import os\n",
    "import sys\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReverseLayerF(Function):\n",
    "\n",
    "    @staticmethod\n",
    "    def forward(ctx, x, alpha):\n",
    "        ctx.alpha = alpha\n",
    "\n",
    "        return x.view_as(x)\n",
    "\n",
    "    @staticmethod\n",
    "    def backward(ctx, grad_output):\n",
    "        output = grad_output.neg() * ctx.alpha\n",
    "\n",
    "        return output, None\n",
    "\n",
    "class DANN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(DANN, self).__init__()\n",
    "        self.feature = nn.Sequential(\n",
    "                    nn.Conv2d(3, 64, kernel_size=5),\n",
    "                    nn.BatchNorm2d(64),\n",
    "                    nn.MaxPool2d(2),\n",
    "                    nn.ReLU(True),\n",
    "                    nn.Conv2d(64, 50, kernel_size=5),\n",
    "                    nn.BatchNorm2d(50),\n",
    "                    nn.Dropout2d(),\n",
    "                    nn.MaxPool2d(2),\n",
    "                    nn.ReLU(True)\n",
    "                )\n",
    "                \n",
    "        self.avgpool=nn.AdaptiveAvgPool2d((5,5))\n",
    "        self.classifier = nn.Sequential(\n",
    "                    nn.Linear(50 * 4 * 4, 100),\n",
    "                    nn.BatchNorm1d(100),\n",
    "                    nn.ReLU(True),\n",
    "                    nn.Dropout(),\n",
    "                    nn.Linear(100, 100),\n",
    "                    nn.BatchNorm1d(100),\n",
    "                    nn.ReLU(True),\n",
    "                    nn.Linear(100, 10),\n",
    "                )\n",
    "\n",
    "\n",
    "        self.domain_classifier = nn.Sequential(\n",
    "                    nn.Linear(50 * 4 * 4, 100),\n",
    "                    nn.BatchNorm1d(100),\n",
    "                    nn.ReLU(True),\n",
    "                    nn.Linear(100, 2),\n",
    "                )\n",
    "    def forward(self, input_data, alpha):\n",
    "        input_data = input_data.expand(input_data.data.shape[0], 3, 28, 28)\n",
    "        feature = self.feature(input_data)\n",
    "        feature = feature.view(-1, 50 * 4 * 4)\n",
    "        reverse_feature = ReverseLayerF.apply(feature, alpha)\n",
    "        class_output = self.classifier(feature)\n",
    "        domain_output = self.domain_classifier(reverse_feature)\n",
    "\n",
    "        return class_output, domain_output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class ReverseLayerF(Function):\n",
    "\n",
    "    @staticmethod\n",
    "    def forward(ctx, x, alpha):\n",
    "        ctx.alpha = alpha\n",
    "\n",
    "        return x.view_as(x)\n",
    "\n",
    "    @staticmethod\n",
    "    def backward(ctx, grad_output):\n",
    "        output = grad_output.neg() * ctx.alpha\n",
    "\n",
    "        return output, None\n",
    "\n",
    "\n",
    "class DANN_with_avg(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(DANN, self).__init__()\n",
    "        self.feature = nn.Sequential(\n",
    "                    nn.Conv2d(3, 32, kernel_size=5),\n",
    "                    nn.BatchNorm2d(32),\n",
    "                    nn.MaxPool2d(2),\n",
    "                    nn.ReLU(True),\n",
    "                    nn.Conv2d(32, 48, kernel_size=5),\n",
    "                    nn.BatchNorm2d(48),\n",
    "                    nn.Dropout2d(),\n",
    "                    nn.MaxPool2d(2),\n",
    "                    nn.ReLU(True)\n",
    "                )\n",
    "                \n",
    "        self.avgpool=nn.AdaptiveAvgPool2d((5,5))\n",
    "        self.classifier = nn.Sequential(\n",
    "                    nn.Linear(48*5*5, 100),\n",
    "                    nn.BatchNorm1d(100),\n",
    "                    nn.ReLU(True),\n",
    "                    nn.Dropout(),\n",
    "                    nn.Linear(100, 100),\n",
    "                    nn.BatchNorm1d(100),\n",
    "                    nn.ReLU(True),\n",
    "                    nn.Linear(100, 10),\n",
    "                )\n",
    "\n",
    "\n",
    "        self.domain_classifier = nn.Sequential(\n",
    "                    nn.Linear(48*5*5, 100),\n",
    "                    nn.BatchNorm1d(100),\n",
    "                    nn.ReLU(True),\n",
    "                    nn.Linear(100, 2),\n",
    "                )\n",
    "    def forward(self,x,alpha):\n",
    "        x = x.expand(x.data.shape[0], 3, 28,28)\n",
    "        x=self.feature(x)\n",
    "        x=self.avgpool(x)\n",
    "        x=torch.flatten(x,1)\n",
    "        task_predict=self.classifier(x)\n",
    "        x = ReverseLayerF.apply(x,alpha)\n",
    "        domain_predict=self.domain_classifier(x)\n",
    "        return task_predict,domain_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(source, target, net, criterion, optimizer, epoch, use_cuda=True):\n",
    "    net.train() # Sets the module in training mode.\n",
    "\n",
    "    train_loss = 0\n",
    "    correct_source_label = 0\n",
    "    correct_source_domain = 0\n",
    "    correct_target_label = 0\n",
    "    correct_target_domain = 0\n",
    "    total = 0\n",
    "    batch_size = 128\n",
    "\n",
    "    data_target_iter = iter(target)\n",
    "    len_dataloader = min(len(source), len(target))\n",
    "\n",
    "    for batch_idx, (inputs, source_label) in enumerate(source):\n",
    "\n",
    "        p = float(batch_idx + epoch * len_dataloader) / (100 * len_dataloader)\n",
    "        alpha = 2. / (1. + np.exp(-10 * p)) - 1\n",
    "\n",
    "        batch_size = inputs.size(0)\n",
    "        total += batch_size\n",
    "\n",
    "        # Feed source image to the network\n",
    "        source_label = source_label.type(torch.LongTensor)\n",
    "        domain_label = torch.zeros(batch_size).long()\n",
    "\n",
    "        if use_cuda:\n",
    "            inputs, source_label, domain_label = inputs.cuda(), source_label.cuda(), domain_label.cuda()\n",
    "            \n",
    "        optimizer.zero_grad()\n",
    "        inputs, source_label = Variable(inputs), Variable(source_label)\n",
    "        \n",
    "        class_output, domain_output = net(inputs, alpha)\n",
    "        \n",
    "        _, predicted = torch.max(class_output.data, 1)\n",
    "        correct_source_label += predicted.eq(source_label.data).cpu().sum().item()\n",
    "        _, predicted = torch.max(domain_output.data, 1)\n",
    "        correct_source_domain += predicted.eq(domain_label.data).cpu().sum().item()\n",
    "\n",
    "        loss_s_label = criterion(class_output, source_label)\n",
    "        loss_s_domain = criterion(domain_output, domain_label)\n",
    "\n",
    "        # Feed target image to the network\n",
    "        target_inputs, target_label = data_target_iter.next()\n",
    "        domain_label = torch.ones(batch_size).long()\n",
    "        if use_cuda:\n",
    "            target_inputs, target_label, domain_label = target_inputs.cuda(), target_label.cuda(), domain_label.cuda()\n",
    "        \n",
    "        class_output, domain_output = net(target_inputs, alpha)\n",
    "        loss_t_domain = criterion(domain_output, domain_label)\n",
    "\n",
    "        _, predicted = torch.max(class_output.data, 1)\n",
    "        correct_target_label += predicted.eq(target_label.data).cpu().sum().item()\n",
    "        _, predicted = torch.max(domain_output.data, 1)\n",
    "        correct_target_domain += predicted.eq(domain_label.data).cpu().sum().item()\n",
    "\n",
    "        loss = loss_s_label + loss_s_domain + loss_t_domain\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "    return correct_source_label, correct_source_domain, correct_target_label, correct_target_domain, total\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader_source, loader_target = load_mnist_data.get_data_loader(1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "e: 0, sl: 0.812700, sd: 0.771933, tl: 0.356917, td: 0.753883\n",
      "e: 5, sl: 0.924817, sd: 0.723617, tl: 0.543133, td: 0.717817\n",
      "e: 10, sl: 0.923350, sd: 0.699183, tl: 0.613767, td: 0.692683\n",
      "e: 15, sl: 0.923067, sd: 0.673167, tl: 0.652200, td: 0.663033\n",
      "e: 20, sl: 0.921650, sd: 0.662083, tl: 0.659450, td: 0.655600\n",
      "e: 25, sl: 0.923850, sd: 0.658233, tl: 0.659100, td: 0.650483\n",
      "e: 30, sl: 0.921950, sd: 0.650933, tl: 0.666117, td: 0.642033\n",
      "e: 35, sl: 0.925167, sd: 0.644967, tl: 0.679200, td: 0.638533\n",
      "e: 40, sl: 0.924517, sd: 0.642667, tl: 0.681700, td: 0.642133\n",
      "e: 45, sl: 0.928100, sd: 0.642783, tl: 0.686800, td: 0.641983\n",
      "e: 50, sl: 0.926233, sd: 0.639600, tl: 0.695450, td: 0.635617\n",
      "e: 55, sl: 0.927800, sd: 0.635750, tl: 0.705617, td: 0.631883\n",
      "e: 60, sl: 0.930483, sd: 0.635367, tl: 0.704117, td: 0.631700\n",
      "e: 65, sl: 0.932100, sd: 0.636417, tl: 0.705617, td: 0.635317\n",
      "e: 70, sl: 0.933567, sd: 0.634850, tl: 0.711250, td: 0.638433\n",
      "e: 75, sl: 0.932433, sd: 0.635183, tl: 0.715167, td: 0.632083\n",
      "e: 80, sl: 0.933933, sd: 0.639250, tl: 0.714817, td: 0.632150\n",
      "e: 85, sl: 0.934567, sd: 0.634417, tl: 0.725583, td: 0.631733\n",
      "e: 90, sl: 0.934150, sd: 0.630167, tl: 0.722450, td: 0.629667\n",
      "e: 95, sl: 0.937017, sd: 0.629183, tl: 0.720417, td: 0.632433\n",
      "e: 100, sl: 0.936300, sd: 0.636667, tl: 0.725517, td: 0.633033\n"
     ]
    }
   ],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "net = DANN_with_avg()\n",
    "if (torch.cuda.is_available()):\n",
    "    torch.cuda.manual_seed_all(42)\n",
    "    cudnn.benchmark = True\n",
    "    net.cuda()\n",
    "    criterion = criterion.cuda()\n",
    "    \n",
    "optimizer = optim.Adam(net.parameters(), lr=0.001) \n",
    "\n",
    "for epoch in range(0, 101):\n",
    "    sl, sd, tl, td, total = train(loader_source, loader_target, net, criterion, optimizer, epoch) \n",
    "\n",
    "    if (epoch % 5 == 0):\n",
    "        print(\"e: %d, sl: %f, sd: %f, tl: %f, td: %f\" % (epoch, sl/total, sd/total, tl/total, td/total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "e: 0, sl: 0.819600, sd: 0.769967, tl: 0.377233, td: 0.735333\n",
      "e: 5, sl: 0.928450, sd: 0.709883, tl: 0.550650, td: 0.712783\n",
      "e: 10, sl: 0.928700, sd: 0.674283, tl: 0.603983, td: 0.668767\n",
      "e: 15, sl: 0.928783, sd: 0.658567, tl: 0.618717, td: 0.653467\n",
      "e: 20, sl: 0.930283, sd: 0.652083, tl: 0.641283, td: 0.647800\n",
      "e: 25, sl: 0.931167, sd: 0.644950, tl: 0.654483, td: 0.642567\n",
      "e: 30, sl: 0.932367, sd: 0.635950, tl: 0.677800, td: 0.626933\n",
      "e: 35, sl: 0.935750, sd: 0.637617, tl: 0.671233, td: 0.630150\n",
      "e: 40, sl: 0.935500, sd: 0.634150, tl: 0.685633, td: 0.622383\n",
      "e: 45, sl: 0.937933, sd: 0.625750, tl: 0.691717, td: 0.619100\n",
      "e: 50, sl: 0.940200, sd: 0.626750, tl: 0.693767, td: 0.620400\n",
      "e: 55, sl: 0.941033, sd: 0.628317, tl: 0.708717, td: 0.619383\n",
      "e: 60, sl: 0.944167, sd: 0.628133, tl: 0.712850, td: 0.618533\n",
      "e: 65, sl: 0.943583, sd: 0.621883, tl: 0.721150, td: 0.616783\n",
      "e: 70, sl: 0.945067, sd: 0.625117, tl: 0.722383, td: 0.618517\n",
      "e: 75, sl: 0.945067, sd: 0.618833, tl: 0.733717, td: 0.613983\n",
      "e: 80, sl: 0.946150, sd: 0.623767, tl: 0.734417, td: 0.616900\n",
      "e: 85, sl: 0.947350, sd: 0.620233, tl: 0.733567, td: 0.613917\n",
      "e: 90, sl: 0.948083, sd: 0.619483, tl: 0.741950, td: 0.608700\n",
      "e: 95, sl: 0.948417, sd: 0.622750, tl: 0.743817, td: 0.616583\n",
      "e: 100, sl: 0.950900, sd: 0.618367, tl: 0.746100, td: 0.610200\n"
     ]
    }
   ],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "net = DANN()\n",
    "if (torch.cuda.is_available()):\n",
    "    torch.cuda.manual_seed_all(42)\n",
    "    cudnn.benchmark = True\n",
    "    net.cuda()\n",
    "    criterion = criterion.cuda()\n",
    "    \n",
    "optimizer = optim.Adam(net.parameters(), lr=0.001) \n",
    "\n",
    "for epoch in range(0, 101):\n",
    "    sl, sd, tl, td, total = train(loader_source, loader_target, net, criterion, optimizer, epoch) \n",
    "\n",
    "    if (epoch % 5 == 0):\n",
    "        print(\"e: %d, sl: %f, sd: %f, tl: %f, td: %f\" % (epoch, sl/total, sd/total, tl/total, td/total))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "f4e5af365abde9565455761093e8e9bc7189c8b509b33061fd0f90eaa1b4d4cb"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 ('ml')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
