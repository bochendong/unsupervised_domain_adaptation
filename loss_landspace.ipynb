{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.init as init\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torch.backends.cudnn as cudnn\n",
    "from torch.autograd import Variable\n",
    "import argparse\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "import os\n",
    "\n",
    "import data_loader\n",
    "import model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_params(net):\n",
    "    for m in net.modules():\n",
    "        if isinstance(m, nn.Conv2d) or isinstance(m, nn.ConvTranspose2d):\n",
    "            init.kaiming_normal_(m.weight, mode='fan_in')\n",
    "            if m.bias is not None:\n",
    "                init.constant_(m.bias, 0)\n",
    "        elif isinstance(m, nn.BatchNorm2d):\n",
    "            init.constant_(m.weight, 1)\n",
    "            init.constant_(m.bias, 0)\n",
    "        elif isinstance(m, nn.Linear):\n",
    "            init.normal_(m.weight, std=1e-3)\n",
    "            if m.bias is not None:\n",
    "                init.constant_(m.bias, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainloader, testloader= data_loader.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(trainloader, net, criterion, optimizer, use_cuda=True):\n",
    "    net.train()\n",
    "    train_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    for batch_idx, (inputs, targets) in enumerate(trainloader):\n",
    "        batch_size = inputs.size(0)\n",
    "        total += batch_size\n",
    "        if use_cuda:\n",
    "            inputs, targets = inputs.cuda(), targets.cuda()\n",
    "        optimizer.zero_grad()\n",
    "        inputs, targets = Variable(inputs), Variable(targets)\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item()*batch_size\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        correct += predicted.eq(targets.data).cpu().sum().item()\n",
    "\n",
    "    return train_loss/total, 100 - 100.*correct/total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(testloader, net, criterion, use_cuda=True):\n",
    "    net.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    for batch_idx, (inputs, targets) in enumerate(testloader):\n",
    "        batch_size = inputs.size(0)\n",
    "        total += batch_size\n",
    "\n",
    "        if use_cuda:\n",
    "            inputs, targets = inputs.cuda(), targets.cuda()\n",
    "        inputs, targets = Variable(inputs), Variable(targets)\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, targets)\n",
    "        test_loss += loss.item()*batch_size\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        correct += predicted.eq(targets.data).cpu().sum().item()\n",
    "\n",
    "    return test_loss/total, 100 - 100.*correct/total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x2115caf85b0>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random.seed(42)\n",
    "np.random.seed(42)\n",
    "torch.manual_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VGG(\n",
      "  (features): Sequential(\n",
      "    (0): Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU(inplace=True)\n",
      "    (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (5): ReLU(inplace=True)\n",
      "    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
      "    (7): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (8): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (9): ReLU(inplace=True)\n",
      "    (10): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (11): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (12): ReLU(inplace=True)\n",
      "    (13): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
      "    (14): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (15): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (16): ReLU(inplace=True)\n",
      "    (17): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (18): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (19): ReLU(inplace=True)\n",
      "    (20): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (21): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (22): ReLU(inplace=True)\n",
      "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
      "  )\n",
      "  (fc): Sequential(\n",
      "    (0): Linear(in_features=4096, out_features=256, bias=True)\n",
      "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU(inplace=True)\n",
      "  )\n",
      "  (classifier): Linear(in_features=256, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "lr = 0.01\n",
    "start_epoch = 1\n",
    "epoches = 30\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "save_folder = 'VGG9'\n",
    "\n",
    "net = model.VGG('VGG9')\n",
    "\n",
    "if (torch.cuda.is_available()):\n",
    "    torch.cuda.manual_seed_all(42)\n",
    "    cudnn.benchmark = True\n",
    "    net.cuda()\n",
    "    criterion = criterion.cuda()\n",
    "\n",
    "init_params(net)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(net.parameters(), lr=lr, weight_decay=0.0005)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists('model_history/' + save_folder):\n",
    "    os.makedirs('model_history/' + save_folder)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\55366\\anaconda3\\envs\\ml\\lib\\site-packages\\torch\\nn\\functional.py:780: UserWarning: Note that order of the arguments: ceil_mode and return_indices will changeto match the args list in nn.MaxPool2d in a future release.\n",
      "  warnings.warn(\"Note that order of the arguments: ceil_mode and return_indices will change\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "e: 0 loss: 2.30273 train_err: 93.913 test_top1: 93.590 test_loss 2.30272 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_loss, train_err = test(trainloader, net, criterion, True)\n",
    "test_loss, test_err = test(testloader, net, criterion, True)\n",
    "status = 'e: %d loss: %.5f train_err: %.3f test_top1: %.3f test_loss %.5f \\n' % (0, train_loss, train_err, test_err, test_loss)\n",
    "print(status)\n",
    "\n",
    "state = {\n",
    "    'acc': 100 - test_err,\n",
    "    'epoch': 0,\n",
    "    'state_dict': net.state_dict()\n",
    "}\n",
    "opt_state = {\n",
    "            'optimizer': optimizer.state_dict()\n",
    "}\n",
    "torch.save(state, 'model_history/' + save_folder + '/model_0.t7')\n",
    "torch.save(opt_state, 'model_history/' + save_folder + '/opt_state_0.t7')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "e: 1 loss: 0.15392 train_err: 4.822 test_top1: 4.150 test_loss 0.12837 \n",
      "\n",
      "e: 2 loss: 0.08119 train_err: 2.532 test_top1: 5.530 test_loss 0.16206 \n",
      "\n",
      "e: 3 loss: 0.07172 train_err: 2.198 test_top1: 3.890 test_loss 0.11408 \n",
      "\n",
      "e: 4 loss: 0.06521 train_err: 1.942 test_top1: 25.930 test_loss 0.88171 \n",
      "\n",
      "e: 5 loss: 0.06440 train_err: 2.030 test_top1: 1.520 test_loss 0.04847 \n",
      "\n",
      "e: 6 loss: 0.05857 train_err: 1.822 test_top1: 1.970 test_loss 0.06804 \n",
      "\n",
      "e: 7 loss: 0.05655 train_err: 1.772 test_top1: 2.900 test_loss 0.10159 \n",
      "\n",
      "e: 8 loss: 0.05327 train_err: 1.657 test_top1: 2.400 test_loss 0.07430 \n",
      "\n",
      "e: 9 loss: 0.05261 train_err: 1.578 test_top1: 4.630 test_loss 0.15590 \n",
      "\n",
      "e: 10 loss: 0.05084 train_err: 1.533 test_top1: 1.570 test_loss 0.04611 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(start_epoch, 10 + 1):\n",
    "    loss, train_err = train(trainloader, net, criterion, optimizer, True)\n",
    "    test_loss, test_err = test(testloader, net, criterion, True)\n",
    "\n",
    "    status = 'e: %d loss: %.5f train_err: %.3f test_top1: %.3f test_loss %.5f \\n' % (epoch, loss, train_err, test_err, test_loss)\n",
    "    print(status)\n",
    "\n",
    "    # Save checkpoint.\n",
    "    acc = 100 - test_err\n",
    "    state = {\n",
    "        'acc': acc,\n",
    "        'epoch': epoch,\n",
    "        'state_dict': net.state_dict(),\n",
    "    }\n",
    "    opt_state = {\n",
    "        'optimizer': optimizer.state_dict()\n",
    "    }\n",
    "    torch.save(state, 'model_history/' + save_folder + '/model_' + str(epoch) + '.t7')\n",
    "    torch.save(opt_state, 'model_history/' + save_folder + '/opt_state_' + str(epoch) + '.t7')"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "f4e5af365abde9565455761093e8e9bc7189c8b509b33061fd0f90eaa1b4d4cb"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 ('ml')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
