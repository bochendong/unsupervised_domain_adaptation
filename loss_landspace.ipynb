{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.init as init\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torch.backends.cudnn as cudnn\n",
    "from torch.autograd import Variable\n",
    "import argparse\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "import os\n",
    "\n",
    "import data_loader\n",
    "import model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_params(net):\n",
    "    for m in net.modules():\n",
    "        if isinstance(m, nn.Conv2d) or isinstance(m, nn.ConvTranspose2d):\n",
    "            init.kaiming_normal_(m.weight, mode='fan_in')\n",
    "            if m.bias is not None:\n",
    "                init.constant_(m.bias, 0)\n",
    "        elif isinstance(m, nn.BatchNorm2d):\n",
    "            init.constant_(m.weight, 1)\n",
    "            init.constant_(m.bias, 0)\n",
    "        elif isinstance(m, nn.Linear):\n",
    "            init.normal_(m.weight, std=1e-3)\n",
    "            if m.bias is not None:\n",
    "                init.constant_(m.bias, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainloader, testloader= data_loader.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(trainloader, net, criterion, optimizer, use_cuda=True):\n",
    "    net.train()\n",
    "    train_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    for batch_idx, (inputs, targets) in enumerate(trainloader):\n",
    "        batch_size = inputs.size(0)\n",
    "        total += batch_size\n",
    "        if use_cuda:\n",
    "            inputs, targets = inputs.cuda(), targets.cuda()\n",
    "        optimizer.zero_grad()\n",
    "        inputs, targets = Variable(inputs), Variable(targets)\n",
    "        outputs = net(inputs)\n",
    "\n",
    "        if (batch_idx == 0):\n",
    "            print(outputs[0])\n",
    "            print(targets[0])\n",
    "        loss = criterion(outputs, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item()*batch_size\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        correct += predicted.eq(targets.data).cpu().sum().item()\n",
    "\n",
    "    return train_loss/total, 100 - 100.*correct/total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(testloader, net, criterion, use_cuda=True):\n",
    "    net.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    for batch_idx, (inputs, targets) in enumerate(testloader):\n",
    "        batch_size = inputs.size(0)\n",
    "        total += batch_size\n",
    "\n",
    "        if use_cuda:\n",
    "            inputs, targets = inputs.cuda(), targets.cuda()\n",
    "        inputs, targets = Variable(inputs), Variable(targets)\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, targets)\n",
    "        test_loss += loss.item()*batch_size\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        correct += predicted.eq(targets.data).cpu().sum().item()\n",
    "\n",
    "    return test_loss/total, 100 - 100.*correct/total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x13127c28590>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random.seed(42)\n",
    "np.random.seed(42)\n",
    "torch.manual_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 0.01\n",
    "start_epoch = 1\n",
    "epoches = 30\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "save_folder = 'VGG9'\n",
    "\n",
    "net = model.VGG('VGG9')\n",
    "\n",
    "if (torch.cuda.is_available()):\n",
    "    torch.cuda.manual_seed_all(42)\n",
    "    cudnn.benchmark = True\n",
    "    net.cuda()\n",
    "    criterion = criterion.cuda()\n",
    "\n",
    "init_params(net)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(net.parameters(), lr=lr, weight_decay=0.0005)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists('model_history/' + save_folder):\n",
    "    os.makedirs('model_history/' + save_folder)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\55366\\anaconda3\\envs\\ml\\lib\\site-packages\\torch\\nn\\functional.py:780: UserWarning: Note that order of the arguments: ceil_mode and return_indices will changeto match the args list in nn.MaxPool2d in a future release.\n",
      "  warnings.warn(\"Note that order of the arguments: ceil_mode and return_indices will change\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "e: 0 loss: 2.30273 train_err: 93.913 test_top1: 93.590 test_loss 2.30272 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_loss, train_err = test(trainloader, net, criterion, True)\n",
    "test_loss, test_err = test(testloader, net, criterion, True)\n",
    "status = 'e: %d loss: %.5f train_err: %.3f test_top1: %.3f test_loss %.5f \\n' % (0, train_loss, train_err, test_err, test_loss)\n",
    "print(status)\n",
    "\n",
    "state = {\n",
    "    'acc': 100 - test_err,\n",
    "    'epoch': 0,\n",
    "    'state_dict': net.state_dict()\n",
    "}\n",
    "opt_state = {\n",
    "            'optimizer': optimizer.state_dict()\n",
    "}\n",
    "torch.save(state, 'model_history/' + save_folder + '/model_0.t7')\n",
    "torch.save(opt_state, 'model_history/' + save_folder + '/opt_state_0.t7')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 0.0015, -0.0166,  0.0094,  0.0096,  0.0246,  0.0047,  0.0005,  0.0049,\n",
      "        -0.0016,  0.0085], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "tensor(2, device='cuda:0')\n",
      "e: 1 loss: 0.15448 train_err: 4.887 test_top1: 3.220 test_loss 0.10485 \n",
      "\n",
      "tensor([-5.8457, -0.2898,  0.6307,  7.6109, -5.4577, -1.7254, -6.6332, -0.0481,\n",
      "        -1.5152, -2.3648], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "tensor(3, device='cuda:0')\n",
      "e: 2 loss: 0.08048 train_err: 2.523 test_top1: 4.190 test_loss 0.14281 \n",
      "\n",
      "tensor([-2.0809, -6.3510, -4.4985, -3.1898,  0.4309,  1.2129, -4.8235, -1.5452,\n",
      "         0.6902,  7.2139], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "tensor(9, device='cuda:0')\n",
      "e: 3 loss: 0.06879 train_err: 2.112 test_top1: 3.490 test_loss 0.10791 \n",
      "\n",
      "tensor([-2.0809, -2.9806, 10.3352,  0.8104, -3.2804, -5.9496, -3.9364,  1.3120,\n",
      "        -0.3134, -2.8726], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "tensor(2, device='cuda:0')\n",
      "e: 4 loss: 0.06302 train_err: 1.912 test_top1: 2.760 test_loss 0.08993 \n",
      "\n",
      "tensor([-2.8120, -3.1607, -5.9611,  1.2441, -5.1409, 12.2488, -3.1956, -3.3119,\n",
      "        -0.1798,  1.8962], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "tensor(5, device='cuda:0')\n",
      "e: 5 loss: 0.06022 train_err: 1.890 test_top1: 2.090 test_loss 0.06921 \n",
      "\n",
      "tensor([-1.5933, -3.0587,  0.9149,  2.4361, -2.7246, -1.9391, -3.7998, -3.8081,\n",
      "         9.3436, -1.2285], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "tensor(8, device='cuda:0')\n",
      "e: 6 loss: 0.05602 train_err: 1.732 test_top1: 2.110 test_loss 0.07021 \n",
      "\n",
      "tensor([ 0.8931, -1.4138, -1.5776, -4.2761, -0.8537,  1.0390, 11.7125, -3.8270,\n",
      "        -0.8608, -2.9741], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "tensor(6, device='cuda:0')\n",
      "e: 7 loss: 0.05686 train_err: 1.723 test_top1: 1.920 test_loss 0.06601 \n",
      "\n",
      "tensor([-2.5541,  8.2372, -0.1960, -1.3235, -0.4163, -1.5421, -1.5657,  0.3062,\n",
      "        -1.2845, -1.9325], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "tensor(1, device='cuda:0')\n",
      "e: 8 loss: 0.05345 train_err: 1.635 test_top1: 2.900 test_loss 0.09125 \n",
      "\n",
      "tensor([-6.4451e-01, -4.5293e+00,  8.4420e-03, -9.0243e-01, -1.4134e+00,\n",
      "         9.9502e-01, -1.1538e+00, -3.8171e+00,  1.0460e+01, -1.4998e+00],\n",
      "       device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "tensor(8, device='cuda:0')\n",
      "e: 9 loss: 0.05251 train_err: 1.578 test_top1: 3.690 test_loss 0.11693 \n",
      "\n",
      "tensor([10.8365, -3.4796,  0.2437, -2.6023, -1.5557, -1.0045, -0.7538, -1.1882,\n",
      "        -1.7414,  0.2093], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "tensor(0, device='cuda:0')\n",
      "e: 10 loss: 0.05253 train_err: 1.668 test_top1: 1.580 test_loss 0.05199 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(start_epoch, 10 + 1):\n",
    "    loss, train_err = train(trainloader, net, criterion, optimizer, True)\n",
    "    test_loss, test_err = test(testloader, net, criterion, True)\n",
    "\n",
    "    status = 'e: %d loss: %.5f train_err: %.3f test_top1: %.3f test_loss %.5f \\n' % (epoch, loss, train_err, test_err, test_loss)\n",
    "    print(status)\n",
    "\n",
    "    # Save checkpoint.\n",
    "    acc = 100 - test_err\n",
    "    state = {\n",
    "        'acc': acc,\n",
    "        'epoch': epoch,\n",
    "        'state_dict': net.state_dict(),\n",
    "    }\n",
    "    opt_state = {\n",
    "        'optimizer': optimizer.state_dict()\n",
    "    }\n",
    "    torch.save(state, 'model_history/' + save_folder + '/model_' + str(epoch) + '.t7')\n",
    "    torch.save(opt_state, 'model_history/' + save_folder + '/opt_state_' + str(epoch) + '.t7')"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "f4e5af365abde9565455761093e8e9bc7189c8b509b33061fd0f90eaa1b4d4cb"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 ('ml')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
